{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Local DuckDB Database\n",
        "\n",
        "This notebook consolidates all the generated CSV data into a single, efficient DuckDB database file (`financial_data.duckdb`). DuckDB is a fast, in-process analytical database that is perfect for this kind of local data workâ€”no server required.\n",
        "\n",
        "This script will:\n",
        "1.  Scan the data directories for all the price, market cap, and financial statement CSV chunks.\n",
        "2.  Combine the chunks for each data type into a single table.\n",
        "3.  Load the two main symbol lists.\n",
        "4.  Create a new DuckDB database file in the `Analysis` directory with seven tables:\n",
        "    -   `prices`\n",
        "    -   `market_caps`\n",
        "    -   `prices_with_market_cap`\n",
        "    -   `statements`\n",
        "    -   `universal_symbols`\n",
        "    -   `fetchable_symbols`\n",
        "    -   `company_profiles`\n",
        "\n",
        "Once this notebook is run, you can connect to the `financial_data.duckdb` file from any other script or notebook to run fast SQL queries on your entire dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed old database file: financial_data.duckdb\n",
            "Created and connected to new DuckDB database: financial_data.duckdb\n",
            "--- Processing table: prices ---\n",
            "Found 4 files to combine for 'prices'.\n",
            "Successfully created and loaded table 'prices'.\n",
            "--- Processing table: market_caps ---\n",
            "Found 4 files to combine for 'market_caps'.\n",
            "Successfully created and loaded table 'market_caps'.\n",
            "--- Processing table: statements ---\n",
            "Found 4 files to combine for 'statements'.\n",
            "Successfully created and loaded table 'statements'.\n",
            "--- Processing table: universal_symbols ---\n",
            "Successfully created and loaded table 'universal_symbols'.\n",
            "--- Processing table: fetchable_symbols ---\n",
            "Successfully created and loaded table 'fetchable_symbols'.\n",
            "--- Processing table: company_profiles ---\n",
            "Successfully created and loaded table 'company_profiles'.\n",
            "--- Processing table: symbol_changes ---\n",
            "Successfully created and loaded table 'symbol_changes'.\n",
            "\n",
            "--- Creating joined prices and market cap table ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f1c9a3ae03404589f69126603ae1a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created 'prices_with_market_cap' table.\n",
            "\n",
            "--- Verifying Database Contents ---\n",
            "Tables in database:\n",
            "                     name\n",
            "0        company_profiles\n",
            "1       fetchable_symbols\n",
            "2             market_caps\n",
            "3                  prices\n",
            "4  prices_with_market_cap\n",
            "5              statements\n",
            "6          symbol_changes\n",
            "7       universal_symbols\n",
            "\n",
            "Row counts for each table:\n",
            "- company_profiles: 36,033 rows\n",
            "- fetchable_symbols: 12,800 rows\n",
            "- market_caps: 26,275,891 rows\n",
            "- prices: 28,853,829 rows\n",
            "- prices_with_market_cap: 26,113,898 rows\n",
            "- statements: 603,196 rows\n",
            "- symbol_changes: 4,939 rows\n",
            "- universal_symbols: 85,850 rows\n",
            "\n",
            "Database creation complete.\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import requests\n",
        "\n",
        "# --- Configuration ---\n",
        "DB_FILE = 'financial_data.duckdb'\n",
        "\n",
        "DATA_PATHS = {\n",
        "    'prices': '../Prices/Price Data/price_data_*.csv',\n",
        "    'market_caps': '../Market Caps/Market Cap Data/market_cap_data_*.csv',\n",
        "    'statements': '../Statements/Statement Data/financials_*.csv',\n",
        "    'universal_symbols': '../Ticker Symbols/Symbol Lists/universal_symbols.csv',\n",
        "    'fetchable_symbols': '../Ticker Symbols/Symbol Lists/fetchable_symbols.csv',\n",
        "    'company_profiles': '../Ticker Symbols/Symbol Lists/company_profiles.csv'\n",
        "}\n",
        "SYMBOL_CHANGE_URL = 'https://financialmodelingprep.com/stable/symbol-change?invalid=false&limit=20000&apikey=REDACTED'\n",
        "\n",
        "# --- Database Creation ---\n",
        "\n",
        "# Remove the old DB file if it exists to start fresh\n",
        "if os.path.exists(DB_FILE):\n",
        "    os.remove(DB_FILE)\n",
        "    print(f\"Removed old database file: {DB_FILE}\")\n",
        "\n",
        "# Connect to DuckDB. It will create the file if it doesn't exist.\n",
        "con = duckdb.connect(database=DB_FILE, read_only=False)\n",
        "print(f\"Created and connected to new DuckDB database: {DB_FILE}\")\n",
        "\n",
        "# --- Table Loading ---\n",
        "\n",
        "def load_chunked_data(table_name, path_glob):\n",
        "    \"\"\"Finds CSVs, combines them, and loads them into a DuckDB table.\"\"\"\n",
        "    print(f\"--- Processing table: {table_name} ---\")\n",
        "    files = glob.glob(path_glob)\n",
        "    if not files:\n",
        "        print(f\"Warning: No files found for glob: {path_glob}\")\n",
        "        return\n",
        "        \n",
        "    print(f\"Found {len(files)} files to combine for '{table_name}'.\")\n",
        "    \n",
        "    # Use DuckDB's powerful CSV reader to handle the concatenation and table creation\n",
        "    # This is much more memory-efficient than loading into pandas first.\n",
        "    con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM read_csv_auto('{path_glob}')\")\n",
        "    \n",
        "    print(f\"Successfully created and loaded table '{table_name}'.\")\n",
        "\n",
        "def load_single_file(table_name, path):\n",
        "    \"\"\"Loads a single CSV file into a DuckDB table.\"\"\"\n",
        "    print(f\"--- Processing table: {table_name} ---\")\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Warning: File not found: {path}\")\n",
        "        return\n",
        "    \n",
        "    con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM read_csv_auto('{path}')\")\n",
        "    print(f\"Successfully created and loaded table '{table_name}'.\")\n",
        "\n",
        "def load_symbol_changes(table_name, url):\n",
        "    \"\"\"Fetches symbol change data from the API and loads it into a DuckDB table.\"\"\"\n",
        "    print(f\"--- Processing table: {table_name} ---\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        if not data:\n",
        "            print(\"Warning: No data received from symbol change API.\")\n",
        "            return\n",
        "            \n",
        "        df = pd.DataFrame(data)\n",
        "        df = df[['date', 'oldSymbol', 'newSymbol']] # Ensure correct columns and order\n",
        "        \n",
        "        # Use DuckDB's `from_df` to load the DataFrame into a table\n",
        "        con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM df\")\n",
        "        print(f\"Successfully created and loaded table '{table_name}'.\")\n",
        "        \n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching symbol change data: {e}\")\n",
        "\n",
        "\n",
        "# Load the chunked data\n",
        "load_chunked_data('prices', DATA_PATHS['prices'])\n",
        "load_chunked_data('market_caps', DATA_PATHS['market_caps'])\n",
        "load_chunked_data('statements', DATA_PATHS['statements'])\n",
        "\n",
        "# Load the single-file symbol lists\n",
        "load_single_file('universal_symbols', DATA_PATHS['universal_symbols'])\n",
        "load_single_file('fetchable_symbols', DATA_PATHS['fetchable_symbols'])\n",
        "load_single_file('company_profiles', DATA_PATHS['company_profiles'])\n",
        "\n",
        "# Load the symbol change data from the API\n",
        "load_symbol_changes('symbol_changes', SYMBOL_CHANGE_URL)\n",
        "\n",
        "# --- Create Joined Table ---\n",
        "print(\"\\n--- Creating joined prices and market cap table ---\")\n",
        "join_query = \"\"\"\n",
        "CREATE TABLE prices_with_market_cap AS\n",
        "SELECT\n",
        "    p.date,\n",
        "    p.symbol,\n",
        "    p.adjClose,\n",
        "    m.marketCap\n",
        "FROM prices p\n",
        "inner JOIN market_caps m ON p.symbol = m.symbol AND p.date = m.date\n",
        "where marketCap is not null and adjClose is not null;\n",
        "\"\"\"\n",
        "con.execute(join_query)\n",
        "print(\"Successfully created 'prices_with_market_cap' table.\")\n",
        "\n",
        "\n",
        "# --- Verification ---\n",
        "print(\"\\n--- Verifying Database Contents ---\")\n",
        "tables = con.execute(\"SHOW TABLES\").df()\n",
        "print(\"Tables in database:\")\n",
        "print(tables)\n",
        "\n",
        "print(\"\\nRow counts for each table:\")\n",
        "for table_name in tables['name']:\n",
        "    count = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
        "    print(f\"- {table_name}: {count:,} rows\")\n",
        "\n",
        "# Close the connection\n",
        "con.close()\n",
        "\n",
        "print(\"\\nDatabase creation complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Query the Database\n",
        "\n",
        "Now that the `financial_data.duckdb` file exists, you can connect to it from any Python script or Jupyter notebook to run SQL queries.\n",
        "\n",
        "-   **Connect in `read_only` mode**: It's a good practice to connect in read-only mode for analysis to prevent accidentally modifying the data.\n",
        "-   **Use `.df()`**: The `.df()` method on a query result will return the data directly into a pandas DataFrame, which is extremely convenient for analysis and visualization.\n",
        "\n",
        "Below is a simple example of how to connect and run a query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Successfully connected to the database. ---\n",
            "   count(DISTINCT symbol)  100M    1B\n",
            "0                   10532  8932  5505\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "import os\n",
        "\n",
        "DB_FILE = 'financial_data.duckdb'\n",
        "\n",
        "if not os.path.exists(DB_FILE):\n",
        "    print(f\"Database file not found at '{DB_FILE}'. Please run the creation script first.\")\n",
        "else:\n",
        "    # Connect to the existing database in read-only mode\n",
        "    con = duckdb.connect(database=DB_FILE, read_only=True)\n",
        "    \n",
        "    print(\"--- Successfully connected to the database. ---\")\n",
        "    \n",
        "    # Example Query: Get the most recent market cap for a few specific stocks\n",
        "    query = \"\"\"\n",
        "    SELECT \n",
        "        count(distinct symbol)\n",
        "        ,count(distinct case when marketCap > 100000000 then symbol end) as \"100M\"\n",
        "        ,count(distinct case when marketCap > 1000000000 then symbol end) as \"1B\"\n",
        "    FROM prices_with_market_cap\n",
        "    ;\n",
        "    \"\"\"\n",
        "    \n",
        "    result_df = con.execute(query).df()\n",
        "    print(result_df)\n",
        "    \n",
        "    # Always remember to close the connection\n",
        "    con.close()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
