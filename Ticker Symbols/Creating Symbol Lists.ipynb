{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2502b9d2",
   "metadata": {},
   "source": [
    "## Filtering out ADRs\n",
    "\n",
    "Unfortunately the isAdr column on the API is garbage. No matter, we can just locally remove all the rows that contain a period in the ticker name. Might I be excluding some good stocks? who knows lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c25d3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to Symbol Lists/adrs_removed.csv\n",
      "Original count: 85850\n",
      "Filtered count: 36054\n",
      "Rows removed: 49796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:25: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Samer Faizi\\AppData\\Local\\Temp\\ipykernel_16592\\1578203897.py:25: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  filtered_df = df[~df['symbol'].str.contains(\"\\.\", na=False)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def filter_universal_symbols():\n",
    "    \"\"\"\n",
    "    Filters out symbols containing '.' from universal_symbols.csv\n",
    "    and saves the result to adrs_removed.csv.\n",
    "    \"\"\"\n",
    "    input_path = 'Symbol Lists/universal_symbols.csv'\n",
    "    output_path = 'Symbol Lists/adrs_removed.csv'\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Read the data\n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {input_path}\")\n",
    "        return\n",
    "\n",
    "    # Tickers with a . in them are ADRs.\n",
    "    filtered_df = df[~df['symbol'].str.contains(\"\\.\", na=False)]\n",
    "\n",
    "    # Record the output\n",
    "    filtered_df.to_csv(output_path, index=False)\n",
    "    print(f\"Filtered data saved to {output_path}\")\n",
    "    print(f\"Original count: {len(df)}\")\n",
    "    print(f\"Filtered count: {len(filtered_df)}\")\n",
    "    print(f\"Rows removed: {len(df) - len(filtered_df)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filter_universal_symbols()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36a760",
   "metadata": {},
   "source": [
    "## Getting Company Profile Data\n",
    "\n",
    "Getting some relevant columns point in time for the tickers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d27122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3e5cdebd4943d1a0d53bf9be3e741e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching Company Profiles:   0%|          | 0/36054 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m         \u001b[38;5;66;03m# Check for rate limit response specifically\u001b[39;00m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# If we get a rate limit error, wait and retry\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connection.py:704\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    703\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    706\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"API_KEY not found in .env file. Please create a .env file with your API key.\")\n",
    "else:\n",
    "    # Read the filtered symbols\n",
    "    input_path = 'Symbol Lists/adrs_removed.csv'\n",
    "    try:\n",
    "        symbols_df = pd.read_csv(input_path)\n",
    "        symbols = symbols_df['symbol'].tolist()\n",
    "\n",
    "        profile_data = []\n",
    "        failed_symbols = []\n",
    "        \n",
    "        # Using tqdm for a progress bar\n",
    "        for symbol in tqdm(symbols, desc=\"Fetching Company Profiles\"):\n",
    "            url = f\"https://financialmodelingprep.com/api/v3/profile/{symbol}?apikey={api_key}\"\n",
    "            \n",
    "            retries = 3\n",
    "            backoff_factor = 0.5\n",
    "            \n",
    "            for i in range(retries):\n",
    "                try:\n",
    "                    response = requests.get(url, timeout=20)\n",
    "                    \n",
    "                    # Check for rate limit response specifically\n",
    "                    if response.status_code == 429:\n",
    "                        # If we get a rate limit error, wait and retry\n",
    "                        retry_after = int(response.headers.get(\"Retry-After\", 1))\n",
    "                        print(f\"Rate limit hit for {symbol}. Retrying in {retry_after} seconds...\")\n",
    "                        time.sleep(retry_after)\n",
    "                        continue # try again\n",
    "                        \n",
    "                    response.raise_for_status() # Raise an exception for other bad status codes (4xx or 5xx)\n",
    "                    data = response.json()\n",
    "\n",
    "                    if data:\n",
    "                        profile = data[0]\n",
    "                        current_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "                        profile_info = {\n",
    "                            'symbol': profile.get('symbol'),\n",
    "                            'companyName': profile.get('companyName'),\n",
    "                            'currency': profile.get('currency'),\n",
    "                            'exchange': profile.get('exchangeShortName'),\n",
    "                            'industry': profile.get('industry'),\n",
    "                            'sector': profile.get('sector'),\n",
    "                            'country': profile.get('country'),\n",
    "                            'ipoDate': profile.get('ipoDate'),\n",
    "                            'isEtf': profile.get('isEtf'),\n",
    "                            'isActivelyTrading': profile.get('isActivelyTrading'),\n",
    "                            'isAdr': profile.get('isAdr'),\n",
    "                            'isFund': profile.get('isFund'),\n",
    "                            'Current Date': current_date\n",
    "                        }\n",
    "                        profile_data.append(profile_info)\n",
    "                    break # Success, break retry loop\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    if i < retries - 1:\n",
    "                        sleep_time = backoff_factor * (2 ** i)\n",
    "                        print(f\"Request for {symbol} failed with {e}. Retrying in {sleep_time:.2f} seconds...\")\n",
    "                        time.sleep(sleep_time)\n",
    "                    else:\n",
    "                        print(f\"Request for {symbol} failed after {retries} retries. Skipping.\")\n",
    "                        failed_symbols.append({'symbol': symbol, 'error': str(e)})\n",
    "            \n",
    "            # A small delay to be respectful to the API provider.\n",
    "            time.sleep(0.05) \n",
    "\n",
    "        # Create DataFrame and save to CSV\n",
    "        if profile_data:\n",
    "            output_df = pd.DataFrame(profile_data)\n",
    "            output_path = 'Symbol Lists/company_profiles.csv'\n",
    "            try:\n",
    "                output_df.to_csv(output_path, index=False)\n",
    "                print(f\"Company profile data saved to {output_path}\")\n",
    "                print(f\"Successfully fetched profiles for {len(output_df)} out of {len(symbols)} symbols.\")\n",
    "            except PermissionError:\n",
    "                print(f\"Error: Could not save to {output_path}. Please make sure the file is not open in another program and you have write permissions.\")\n",
    "        else:\n",
    "            print(\"No profile data was fetched.\")\n",
    "            \n",
    "        if failed_symbols:\n",
    "            failed_df = pd.DataFrame(failed_symbols)\n",
    "            failed_output_path = 'Symbol Lists/failed_to_get_profile.csv'\n",
    "            failed_df.to_csv(failed_output_path, index=False)\n",
    "            print(f\"Failed to fetch {len(failed_symbols)} symbols. Details saved to {failed_output_path}\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {input_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464c077",
   "metadata": {},
   "source": [
    "## Filtering out non-tradable\n",
    "\n",
    "Now we will filter the company profiles to get a clean list of symbols for further analysis. We want to exclude ADRs, ETFs, Funds, and OTC stocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b07f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered symbols saved to Symbol Lists/removing_nonstocks_symbols.csv\n",
      "Original profiles count: 36033\n",
      "Filtered symbols count: 11178\n",
      "Symbols removed: 24855\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_company_profiles():\n",
    "    \"\"\"\n",
    "    Filters the company profiles based on isAdr, isEtf, isFund, and exchange.\n",
    "    Saves the filtered symbols to a new CSV file.\n",
    "    \"\"\"\n",
    "    input_path = 'Symbol lists/company_profiles.csv'\n",
    "    output_path = 'Symbol Lists/removing_nonstocks_symbols.csv'\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "\n",
    "        # Apply the filters\n",
    "        filtered_df = df[\n",
    "            (df['isAdr'] == False) &\n",
    "            (df['isEtf'] == False) &\n",
    "            (df['isFund'] == False) &\n",
    "            (df['exchange'] != 'OTC')\n",
    "        ]\n",
    "        \n",
    "        # Select only the symbol column to save\n",
    "        symbols_to_save = filtered_df[['symbol']]\n",
    "\n",
    "        # Save the filtered symbols to a new CSV file\n",
    "        symbols_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Filtered symbols saved to {output_path}\")\n",
    "        print(f\"Original profiles count: {len(df)}\")\n",
    "        print(f\"Filtered symbols count: {len(symbols_to_save)}\")\n",
    "        print(f\"Symbols removed: {len(df) - len(symbols_to_save)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {input_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function\n",
    "filter_company_profiles()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ade24",
   "metadata": {},
   "source": [
    "## Identifying Delisted Symbols\n",
    "\n",
    "To ensure our symbol list is comprehensive, we need to account for symbols that have changed over time. The following script will use the Symbol Changes API to find any old symbols that have been replaced by the symbols in our `removing_nonstocks_symbols.csv` list. This will give us a list of delisted symbols that correspond to our active tickers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad5857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching symbol changes from the API...\n",
      "Found 4937 total symbol changes.\n",
      "Found 2563 matching changed symbols.\n",
      "Saved the list to ../output/changed_symbols.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def find_matching_old_symbols():\n",
    "    \"\"\"\n",
    "    Finds old symbols from the symbol change API where the new symbol\n",
    "    matches a symbol in our filtered list.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv('API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"API_KEY not found in .env file.\")\n",
    "        return\n",
    "\n",
    "    filtered_symbols_path = 'Symbol Lists/removing_nonstocks_symbols.csv'\n",
    "    output_path = 'Symbol Lists/changed_symbols.csv'\n",
    "\n",
    "    try:\n",
    "        # Read the filtered symbols into a set for fast lookup\n",
    "        filtered_df = pd.read_csv(filtered_symbols_path)\n",
    "        filtered_symbols_set = set(filtered_df['symbol'])\n",
    "        \n",
    "        # Call the symbol change API with a large limit to fetch all changes\n",
    "        # The API defaults to a small limit (e.g., 100), so we must override it.\n",
    "        url = f\"https://financialmodelingprep.com/stable/symbol-change?limit=200000&apikey={api_key}\"\n",
    "        \n",
    "        print(\"Fetching symbol changes from the API...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        symbol_changes = response.json()\n",
    "        print(f\"Found {len(symbol_changes)} total symbol changes.\")\n",
    "\n",
    "        # Find oldSymbols where the newSymbol is in our list\n",
    "        matching_old_symbols = []\n",
    "        for change in symbol_changes:\n",
    "            new_symbol = change.get('newSymbol')\n",
    "            if new_symbol in filtered_symbols_set:\n",
    "                old_symbol = change.get('oldSymbol')\n",
    "                if old_symbol:\n",
    "                    matching_old_symbols.append({'symbol': old_symbol})\n",
    "        \n",
    "        if matching_old_symbols:\n",
    "            # Save the list of old symbols to a new CSV\n",
    "            output_df = pd.DataFrame(matching_old_symbols)\n",
    "            # Remove duplicates\n",
    "            output_df.drop_duplicates(inplace=True)\n",
    "            output_df.to_csv(output_path, index=False)\n",
    "            \n",
    "            print(f\"Found {len(output_df)} matching changed symbols.\")\n",
    "            print(f\"Saved the list to {output_path}\")\n",
    "        else:\n",
    "            print(\"No matching old symbols were found.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {filtered_symbols_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while calling the API: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function\n",
    "find_matching_old_symbols()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2146e",
   "metadata": {},
   "source": [
    "## Combining Symbol Lists\n",
    "\n",
    "Finally, we'll combine our list of currently active symbols (`removing_nonstocks_symbols.csv`) with our list of historical symbols (`changed_symbols.csv`) to create a complete, deduplicated list of all symbols we need to fetch data for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42dcd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 11178 symbols from 'removing_nonstocks_symbols.csv' and 2563 symbols from 'changed_symbols.csv'.\n",
      "Total symbols before deduplication: 13741\n",
      "Removed 941 duplicate symbols.\n",
      "Final count of fetchable symbols: 12800\n",
      "Saved the final list to Symbol Lists/fetchable_symbols.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def combine_and_deduplicate_symbols():\n",
    "    \"\"\"\n",
    "    Combines filtered_symbols.csv and changed_symbols.csv, removes duplicates,\n",
    "    and saves the result to fetchable_symbols.csv.\n",
    "    \"\"\"\n",
    "    filtered_path = 'Symbol Lists/removing_nonstocks_symbols.csv'\n",
    "    changed_path = 'Symbol Lists/changed_symbols.csv'\n",
    "    output_path = 'Symbol Lists/fetchable_symbols.csv'\n",
    "\n",
    "    try:\n",
    "        filtered_df = pd.read_csv(filtered_path)\n",
    "        changed_df = pd.read_csv(changed_path)\n",
    "\n",
    "        # Combine the two dataframes\n",
    "        combined_df = pd.concat([filtered_df, changed_df], ignore_index=True)\n",
    "        \n",
    "        original_count = len(combined_df)\n",
    "        \n",
    "        # Drop duplicates based on the 'symbol' column\n",
    "        deduplicated_df = combined_df.drop_duplicates(subset=['symbol'])\n",
    "        \n",
    "        final_count = len(deduplicated_df)\n",
    "\n",
    "        # Save the final list to a new CSV\n",
    "        deduplicated_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"Combined {len(filtered_df)} symbols from '{filtered_path.split('/')[-1]}' and {len(changed_df)} symbols from '{changed_path.split('/')[-1]}'.\")\n",
    "        print(f\"Total symbols before deduplication: {original_count}\")\n",
    "        print(f\"Removed {original_count - final_count} duplicate symbols.\")\n",
    "        print(f\"Final count of fetchable symbols: {final_count}\")\n",
    "        print(f\"Saved the final list to {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: A required file was not found. Please ensure both 'filtered_symbols.csv' and 'changed_symbols.csv' are in the 'output' directory.\")\n",
    "        print(f\"Missing file details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function\n",
    "combine_and_deduplicate_symbols()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
